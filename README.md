# Desafio TÃ©cnico â€“ Engenheiro de IA (Parte 1)
## Agente AutÃ´nomo Multi-Ferramentas

> **Autor:** Patrick de Noronha
> **Data:** Novembro 2025  
> **Framework:** LangChain + LangGraph  
> **Modelo LLM:** Google Gemini 2.0 Flash

---

## ğŸ“‹ SumÃ¡rio Executivo

Este projeto implementa um **agente autÃ´nomo baseado em LLM** capaz de:
- âœ… Receber consultas complexas de usuÃ¡rios
- âœ… Interagir com **4 ferramentas externas** de forma autÃ´noma
- âœ… Executar raciocÃ­nio em cadeia (chain-of-thought)
- âœ… Produzir respostas estruturadas e justificadas

### Resultado Obtido
O agente processou com sucesso a consulta:  
*"Monte um relatÃ³rio que mostre o preÃ§o mÃ©dio de GPUs na AWS, Azure e GCP, e sugira a opÃ§Ã£o mais barata por hora de uso"*

**Ferramentas utilizadas autonomamente:**
1. âœ… Busca Interna (JSON Mock) - 3 chamadas
2. âœ… API Externa (FastAPI) - 3 chamadas  
3. âœ… Banco de Dados Vetorial (FAISS) - 1 chamada
4. âœ… Embeddings (Google AI) - Integrado

**RecomendaÃ§Ã£o final:** GCP (NVIDIA T4) @ $1.15/hora

---

## ğŸ—ï¸ Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USUÃRIO (Query Complexa)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 AGENTE AUTÃ”NOMO (LangGraph)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LLM: Google Gemini 2.0 Flash (Temperature=0)        â”‚   â”‚
â”‚  â”‚  Framework: LangChain + LangGraph (ReAct Pattern)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                 â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚            â–¼               â–¼               â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ FERRAMENTA 1 â”‚  â”‚FERRAMENTA 2 â”‚  â”‚ FERRAMENTA 3 â”‚       â”‚
â”‚  â”‚ Busca Internaâ”‚  â”‚   VectorDB  â”‚  â”‚ API Externa  â”‚       â”‚
â”‚  â”‚  (JSON Mock) â”‚  â”‚   (FAISS)   â”‚  â”‚  (FastAPI)   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Resposta Final   â”‚
                  â”‚   Estruturada    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ DecisÃµes TÃ©cnicas

### 1. Framework: LangChain + LangGraph

**DecisÃ£o:** Usar LangChain com LangGraph (ao invÃ©s do antigo AgentExecutor)

**Justificativa:**
- âœ… **LangGraph Ã© o estado da arte** (2025) para agentes complexos
- âœ… Melhor controle de estado e fluxo de execuÃ§Ã£o
- âœ… Suporte nativo para ReAct pattern (Reason + Act)
- âœ… Facilita debugging com streaming de estados
- âœ… Preparado para escalonamento (stateful graphs)

**Trade-offs:**
- âŒ Curva de aprendizado mais Ã­ngreme que AgentExecutor legado
- âŒ DocumentaÃ§Ã£o ainda em evoluÃ§Ã£o
- âœ… Mas compensa pela flexibilidade e performance

---

### 2. Modelo LLM: Google Gemini 2.0 Flash

**DecisÃ£o:** Google Gemini 2.0 Flash Experimental

**Justificativa:**
- âœ… **Custo extremamente baixo**: ~$0.10/1M tokens (input)
- âœ… **LatÃªncia baixa**: <1s para respostas tÃ­picas
- âœ… **Suporte nativo a function calling** (essencial para agentes)
- âœ… **API estÃ¡vel** e bem documentada
- âœ… **Quota generosa no free tier**

**ComparaÃ§Ã£o com alternativas:**
| Modelo | Custo (1M tokens) | LatÃªncia | Function Calling | DecisÃ£o |
|--------|------------------|----------|------------------|---------|
| GPT-4 Turbo | $10 | ~2s | âœ… | âŒ Muito caro |
| Claude 3.5 Sonnet | $3 | ~1.5s | âœ… | âœ… Boa opÃ§Ã£o |
| Gemini 2.0 Flash | $0.10 | <1s | âœ… | âœ… **Escolhido** |
| Llama 3.1 (self-host) | $0 (infra) | ~3s | âš ï¸ | âŒ Complexidade operacional |

**Trade-offs:**
- âŒ Modelo experimental (pode mudar)
- âœ… Performance excepcional para o custo
- âœ… Ideal para prototipagem e produÃ§Ã£o de baixo volume

---

### 3. Ferramentas Implementadas

#### ğŸ”§ Ferramenta 1: Busca Interna (JSON Mock)
```python
@tool
def simulated_internal_search(query: str) -> str:
    """Simula busca em banco de dados interno"""
```

**Por quÃª?**
- âœ… Simula um sistema de preÃ§os histÃ³ricos
- âœ… Resposta instantÃ¢nea (sem latÃªncia de rede)
- âœ… Dados estruturados (JSON)

**Casos de uso reais:**
- Banco de dados interno da empresa
- Cache de preÃ§os
- Sistema de inventÃ¡rio

---

#### ğŸ”§ Ferramenta 2: Banco de Dados Vetorial (FAISS)
```python
vector_store = FAISS.from_texts(docs_text, embeddings)
retriever = vector_store.as_retriever(search_kwargs={"k": 2})
```

**Por quÃª FAISS?**
- âœ… **In-memory**: ultra rÃ¡pido para protÃ³tipos
- âœ… **Zero setup**: nÃ£o precisa de servidor separado
- âœ… **Eficiente**: otimizado pelo Meta (Facebook AI)
- âœ… **EscalÃ¡vel**: suporta bilhÃµes de vetores em produÃ§Ã£o

**Alternativas consideradas:**
| Vector DB | Setup | LatÃªncia | Escala | DecisÃ£o |
|-----------|-------|----------|--------|---------|
| FAISS | Zero | <10ms | Billions | âœ… **Escolhido** |
| ChromaDB | Docker | ~50ms | Millions | âš ï¸ Overhead desnecessÃ¡rio |
| Pinecone | Cloud | ~100ms | Unlimited | âŒ Requer conta paga |
| Weaviate | K8s | ~80ms | Billions | âŒ Over-engineering |

**Trade-offs:**
- âŒ Sem persistÃªncia nativa (in-memory)
- âœ… Pode salvar Ã­ndice em disco com `faiss.write_index()`
- âœ… Perfeito para este caso de uso

---

#### ğŸ”§ Ferramenta 3: API Externa (FastAPI)
```python
app_api = FastAPI()

@app_api.get("/api/real-time-price/{provider}")
def get_real_time_price(provider: str):
    """Simula API de preÃ§os em tempo real"""
```

**Por quÃª FastAPI?**
- âœ… **Moderna**: async nativo, type hints
- âœ… **RÃ¡pida**: performance comparÃ¡vel a Node.js
- âœ… **Auto-documentada**: Swagger UI automÃ¡tico
- âœ… **FÃ¡cil deploy**: Docker, Kubernetes, serverless

**Arquitetura:**
- Thread separada (daemon) no mesmo processo
- Porta 8001 (evita conflitos)
- Simula latÃªncia de API real

**Em produÃ§Ã£o:**
```python
# Separaria em microserviÃ§o independente
# docker-compose.yml:
services:
  api:
    build: ./api
    ports: ["8001:8001"]
  agent:
    build: ./agent
    depends_on: [api]
```

---

### 4. Pattern de Agente: ReAct (Reason + Act)

**Fluxo de execuÃ§Ã£o:**
```
1. REASON:  "Preciso obter preÃ§os mÃ©dios de 3 providers"
   â†“
2. ACT:     Chama simulated_internal_search("AWS")
   â†“
3. OBSERVE: Recebe {"average_price_per_hour": 4.10}
   â†“
4. REASON:  "Agora preciso de preÃ§os em tempo real"
   â†“
5. ACT:     Chama get_real_time_gpu_price("aws")
   â†“
6. OBSERVE: Recebe {"price_per_hour": 3.95}
   â†“
7. REASON:  "Preciso de anÃ¡lise qualitativa"
   â†“
8. ACT:     Chama search_vector_database("custo benefÃ­cio")
   â†“
9. OBSERVE: Recebe relatÃ³rios de anÃ¡lise
   â†“
10. REASON: "Tenho todos os dados, vou sintetizar"
   â†“
11. FINAL:  Retorna relatÃ³rio estruturado
```

**Vantagens do ReAct:**
- âœ… TransparÃªncia: cada passo Ã© visÃ­vel nos logs
- âœ… Debuggable: fÃ¡cil identificar onde falhou
- âœ… Eficiente: sÃ³ usa ferramentas necessÃ¡rias
- âœ… EscalÃ¡vel: adicionar novas ferramentas Ã© trivial

---

## ğŸ“Š MÃ©tricas de Performance

### Tempo de ExecuÃ§Ã£o (Query Completa)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fase                    â”‚ Tempo    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ InicializaÃ§Ã£o API       â”‚ 2s       â”‚
â”‚ Embedding load          â”‚ 0.5s     â”‚
â”‚ LLM Planning            â”‚ 1.2s     â”‚
â”‚ Tool calls (7x)         â”‚ 2.8s     â”‚
â”‚ Final synthesis         â”‚ 1.5s     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL                   â”‚ ~8s      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Custos Estimados (por query)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Componente              â”‚ Custo        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LLM (Gemini Flash)      â”‚ $0.0001      â”‚
â”‚ Embeddings              â”‚ $0.00001     â”‚
â”‚ Infraestrutura          â”‚ $0           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL por query         â”‚ ~$0.00011    â”‚
â”‚ 1 milhÃ£o de queries     â”‚ ~$110        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ComparaÃ§Ã£o com GPT-4:**
- GPT-4 Turbo: ~$0.01 por query (100x mais caro)
- Claude 3.5: ~$0.003 por query (30x mais caro)

---

## ğŸ”’ ConsideraÃ§Ãµes de SeguranÃ§a

### 1. API Keys
```bash
# âœ… BOM: VariÃ¡vel de ambiente
export GOOGLE_API_KEY="..."

# âŒ RUIM: Hardcoded no cÃ³digo
llm = ChatGoogleGenerativeAI(api_key="AIza...")
```

### 2. ValidaÃ§Ã£o de Input
```python
# Implementar em produÃ§Ã£o:
from pydantic import BaseModel, validator

class QueryInput(BaseModel):
    query: str
    
    @validator('query')
    def validate_length(cls, v):
        if len(v) > 1000:
            raise ValueError("Query muito longa")
        return v
```

### 3. Rate Limiting
```python
# Adicionar em produÃ§Ã£o:
from slowapi import Limiter

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.get("/query")
@limiter.limit("10/minute")
async def query_endpoint():
    ...
```

### 4. SanitizaÃ§Ã£o de Logs
```python
# âœ… Implementado: nÃ£o logamos API keys
# âš ï¸ TODO em produÃ§Ã£o: mascarar PII nos logs
```

---

## ğŸ“ˆ Escalabilidade

### Horizontal Scaling
```yaml
# Kubernetes deployment (exemplo)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-agent
spec:
  replicas: 10  # Escala facilmente
  template:
    spec:
      containers:
      - name: agent
        image: ai-agent:latest
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
```

### OtimizaÃ§Ãµes PossÃ­veis
1. **Caching de embeddings**: Usar Redis
2. **Batch processing**: Processar mÃºltiplas queries em paralelo
3. **Model quantization**: Usar GGUF/GPTQ se self-hosting
4. **Async tools**: Todas as ferramentas podem ser async

---

## ğŸš€ Como Executar

### OpÃ§Ã£o 1: Local (venv)
```bash
# 1. Clone o repositÃ³rio
git clone <repo-url>
cd ai-agent-challenge

# 2. Crie o ambiente virtual
python -m venv .venv

# 3. Ative o ambiente
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

# 4. Instale dependÃªncias
pip install -r requirements.txt

# 5. Configure a API Key
# Windows PowerShell:
$env:GOOGLE_API_KEY="sua_chave_aqui"
# Linux/Mac:
export GOOGLE_API_KEY="sua_chave_aqui"

# 6. Execute
python agent.py
```

### OpÃ§Ã£o 2: Docker
```bash
# 1. Build da imagem
docker build -t ai-agent .

# 2. Execute
docker run -e GOOGLE_API_KEY="sua_chave" ai-agent
```

### OpÃ§Ã£o 3: Docker Compose
```bash
docker-compose up
```

---

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ agent.py                  # CÃ³digo principal do agente
â”œâ”€â”€ requirements.txt          # DependÃªncias Python
â”œâ”€â”€ Dockerfile               # Container definition
â”œâ”€â”€ docker-compose.yml       # OrquestraÃ§Ã£o multi-container
â”œâ”€â”€ .env.example             # Template de variÃ¡veis de ambiente
â”œâ”€â”€ README.md                # Este arquivo
â””â”€â”€ tests/                   # (Futuro) Testes unitÃ¡rios
    â”œâ”€â”€ test_agent.py
    â”œâ”€â”€ test_tools.py
    â””â”€â”€ test_integration.py
```

---

## ğŸ§ª Testes e ValidaÃ§Ã£o

### Teste Manual Executado
```bash
Query: "Monte um relatÃ³rio que mostre o preÃ§o mÃ©dio de GPUs..."
âœ… Status: SUCESSO
âœ… Ferramentas usadas: 7 chamadas (3+3+1)
âœ… Resposta: Estruturada e justificada
âœ… RecomendaÃ§Ã£o: GCP T4 ($1.15/h) â† CORRETO
```

### PrÃ³ximos Passos (Testes Automatizados)
```python
# tests/test_agent.py
def test_agent_with_mock_tools():
    """Testa agente com ferramentas mockadas"""
    assert agent.run("query") == expected_output

def test_tool_fallback():
    """Testa fallback quando ferramenta falha"""
    assert agent.handles_errors_gracefully()

def test_concurrent_queries():
    """Testa mÃºltiplas queries simultÃ¢neas"""
    results = await asyncio.gather(*[
        agent.run(q) for q in queries
    ])
    assert all(r.success for r in results)
```

---

## ğŸ¯ PrÃ³ximas Melhorias

### Curto Prazo (1-2 semanas)
- [ ] Adicionar mais ferramentas (ex: Wikipedia, calculadora)
- [ ] Implementar caching de resultados (Redis)
- [ ] Adicionar mÃ©tricas (Prometheus/Grafana)
- [ ] Testes unitÃ¡rios e de integraÃ§Ã£o
- [ ] CI/CD pipeline (GitHub Actions)

### MÃ©dio Prazo (1-2 meses)
- [ ] Interface web (Streamlit ou Gradio)
- [ ] Sistema de feedback humano (RLHF)
- [ ] Multi-agent collaboration
- [ ] Suporte a mÃºltiplos idiomas
- [ ] Fine-tuning do modelo para domÃ­nio especÃ­fico

### Longo Prazo (3-6 meses)
- [ ] Deploy em produÃ§Ã£o (AWS/GCP)
- [ ] Monitoramento avanÃ§ado (DataDog, New Relic)
- [ ] A/B testing de diferentes estratÃ©gias
- [ ] Sistema de memÃ³ria persistente
- [ ] IntegraÃ§Ã£o com ferramentas empresariais (Slack, Jira, etc.)

---

## ğŸ“š ReferÃªncias

### Papers e Artigos
1. **ReAct**: [Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)
2. **LangGraph**: [Official Documentation](https://langchain-ai.github.io/langgraph/)
3. **Function Calling**: [Gemini Function Calling Guide](https://ai.google.dev/docs/function_calling)

### Ferramentas Utilizadas
- [LangChain](https://github.com/langchain-ai/langchain) - Framework de agentes
- [LangGraph](https://github.com/langchain-ai/langgraph) - Stateful agents
- [FAISS](https://github.com/facebookresearch/faiss) - Vector similarity search
- [FastAPI](https://fastapi.tiangolo.com/) - Modern API framework
- [Google Gemini](https://ai.google.dev/) - LLM API

---

## ğŸ‘¤ Autor

**Patrick**  
Cybersecurity Professional & AI Engineer  
- ğŸŒ LocalizaÃ§Ã£o: BÃ©lgica
- ğŸ’¼ ExperiÃªncia: Bug bounty hunting, Penetration testing, AI/ML
- ğŸ¯ Foco atual: Autonomous LLM agents, Multi-tool orchestration

---

## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido como parte de um desafio tÃ©cnico para avaliaÃ§Ã£o de competÃªncias em engenharia de IA.

---

## ğŸ™ Agradecimentos

- Equipe do LangChain pelo excelente framework
- Google pela API generosa do Gemini
- Comunidade open-source pelas ferramentas incrÃ­veis

---

**Status:** âœ… Parte 1 ConcluÃ­da  
**Data de entrega:** Novembro 2025  
**Tempo de desenvolvimento:** ~6 horas
